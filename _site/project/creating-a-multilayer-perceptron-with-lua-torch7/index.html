<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.3.1 by Michael Rose
  Copyright 2017 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE.txt
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin SEO -->









<title>            Creating a multi-layer perceptron to train on MNIST dataset      Elvin Ouyang’s Blog      </title>




<meta name="description" content="In this post I will share my work that I finished for the Machine Learning II (Deep Learning) course at GWU. The mini-project is written with Torch7, a package for Lua programming language that enables the calculation of tensors. The codes I’ve included in this post are a combination of borrowed codes from online tutorials, my course notes, and my own creation. In my following posts, I will create another post to explain the same model using PyTorch, an amazing equivalent package to Torch7 that is running on python.">




<meta name="author" content="Chuanye (Elvin) Ouyang">

<meta property="og:locale" content="en">
<meta property="og:site_name" content="Elvin Ouyang's Blog">
<meta property="og:title" content="Creating a multi-layer perceptron to train on MNIST dataset">


  <link rel="canonical" href="http://localhost:4000/project/creating-a-multilayer-perceptron-with-lua-torch7/">
  <meta property="og:url" content="http://localhost:4000/project/creating-a-multilayer-perceptron-with-lua-torch7/">



  <meta property="og:description" content="In this post I will share my work that I finished for the Machine Learning II (Deep Learning) course at GWU. The mini-project is written with Torch7, a package for Lua programming language that enables the calculation of tensors. The codes I’ve included in this post are a combination of borrowed codes from online tutorials, my course notes, and my own creation. In my following posts, I will create another post to explain the same model using PyTorch, an amazing equivalent package to Torch7 that is running on python.">





  

  





  <meta property="og:type" content="article">
  <meta property="article:published_time" content="2017-09-30T00:00:00-04:00">








  <script type="application/ld+json">
    {
      "@context" : "http://schema.org",
      "@type" : "Person",
      "name" : "Elvin Ouyang",
      "url" : "http://localhost:4000",
      "sameAs" : ["https://twitter.com/elvinouyang","https://www.linkedin.com/in/ouyangchuanye/"]
    }
  </script>






<!-- end SEO -->


<link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="Elvin Ouyang's Blog Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/main.css">

<!--[if lte IE 9]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->

<meta http-equiv="cleartype" content="on">
    <!-- start custom head snippets -->

<!-- insert favicons. use http://realfavicongenerator.net/ -->

<!-- end custom head snippets -->
  </head>

  <body class="layout--single">

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->
    <div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <a class="site-title" href="http://localhost:4000/">Elvin Ouyang's Blog</a>
        <ul class="visible-links">
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/about/">About</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/projects/">Projects</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/study-notes/">Study Notes</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/categories/">Category</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/tags/">Tag</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/resources/">Resources</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/sitemap/">Sitemap</a></li>
          
        </ul>
        <button><div class="navicon"></div></button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    



<div id="main" role="main">
  
  <div class="sidebar sticky">
  

<div itemscope itemtype="http://schema.org/Person">

  
    <div class="author__avatar">
      
        <img src="http://localhost:4000/assets/images/bio-photo.jpeg" class="author__avatar" alt="Chuanye (Elvin) Ouyang" itemprop="image">
      
    </div>
  

  <div class="author__content">
    <h3 class="author__name" itemprop="name">Chuanye (Elvin) Ouyang</h3>
    
      <p class="author__bio" itemprop="description">
        Chuanye (Elvin) Ouyang is a young professional in data science, risk analysis, compliance evaluation, and forensic analytics.
      </p>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="http://schema.org/Place">
          <i class="fa fa-fw fa-map-marker" aria-hidden="true"></i> <span itemprop="name">Washington, DC</span>
        </li>
      

      

      

      

      
        <li>
          <a href="https://twitter.com/elvinouyang" itemprop="sameAs">
            <i class="fa fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter
          </a>
        </li>
      

      

      

      
        <li>
          <a href="https://www.linkedin.com/in/ouyangchuanye" itemprop="sameAs">
            <i class="fa fa-fw fa-linkedin-square" aria-hidden="true"></i> LinkedIn
          </a>
        </li>
      

      

      

      

      

      
        <li>
          <a href="https://github.com/ElvinOuyang" itemprop="sameAs">
            <i class="fa fa-fw fa-github" aria-hidden="true"></i> GitHub
          </a>
        </li>
      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs">
      <i class="fa fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>


  <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
    <meta itemprop="headline" content="Creating a multi-layer perceptron to train on MNIST dataset">
    <meta itemprop="description" content="In this post I will share my work that I finished for the Machine Learning II (Deep Learning) course at GWU. The mini-project is written with Torch7, a package for Lua programming language that enables the calculation of tensors. The codes I’ve included in this post are a combination of borrowed codes from online tutorials, my course notes, and my own creation. In my following posts, I will create another post to explain the same model using PyTorch, an amazing equivalent package to Torch7 that is running on python.">
    <meta itemprop="datePublished" content="September 30, 2017">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 class="page__title" itemprop="headline">Creating a multi-layer perceptron to train on MNIST dataset
</h1>
          
            <p class="page__meta"><i class="fa fa-clock-o" aria-hidden="true"></i> 




  4 minute read
</p>
          
        </header>
      

      <section class="page__content" itemprop="text">
        <p>In this post I will share my work that I finished for the Machine Learning II (Deep Learning) course at GWU. The mini-project is written with Torch7, a package for Lua programming language that enables the calculation of tensors. The codes I’ve included in this post are a combination of borrowed codes from online tutorials, my course notes, and my own creation. In my following posts, I will create another post to explain the same model using PyTorch, an amazing equivalent package to Torch7 that is running on python.</p>

<p>The MNIST database contains 28 by 28 pixel pictures of hand-written numbers and labels of its number value. The database is a classic machine learning data prototype, with countless data science students and scholars trying to build models that can automatically tag the pictures with the true number. The data has been preloaded to a Torch7 package and can be easily retrieved for study, like below:</p>

<div class="language-lua highlighter-rouge"><pre class="highlight"><code><span class="nb">require</span> <span class="s1">'dp'</span>

<span class="c1">-- Load the mnist data set</span>
<span class="n">ds</span> <span class="o">=</span> <span class="n">dp</span><span class="p">.</span><span class="n">Mnist</span><span class="p">()</span>

<span class="c1">-- Extract training, validation and test sets</span>
<span class="n">trainInputs</span> <span class="o">=</span> <span class="n">ds</span><span class="p">:</span><span class="n">get</span><span class="p">(</span><span class="s1">'train'</span><span class="p">,</span> <span class="s1">'inputs'</span><span class="p">,</span> <span class="s1">'bchw'</span><span class="p">)</span>
<span class="n">trainTargets</span> <span class="o">=</span> <span class="n">ds</span><span class="p">:</span><span class="n">get</span><span class="p">(</span><span class="s1">'train'</span><span class="p">,</span> <span class="s1">'targets'</span><span class="p">,</span> <span class="s1">'b'</span><span class="p">)</span>
<span class="n">validInputs</span> <span class="o">=</span> <span class="n">ds</span><span class="p">:</span><span class="n">get</span><span class="p">(</span><span class="s1">'valid'</span><span class="p">,</span> <span class="s1">'inputs'</span><span class="p">,</span> <span class="s1">'bchw'</span><span class="p">)</span>
<span class="n">validTargets</span> <span class="o">=</span> <span class="n">ds</span><span class="p">:</span><span class="n">get</span><span class="p">(</span><span class="s1">'valid'</span><span class="p">,</span> <span class="s1">'targets'</span><span class="p">,</span> <span class="s1">'b'</span><span class="p">)</span>
<span class="n">testInputs</span> <span class="o">=</span> <span class="n">ds</span><span class="p">:</span><span class="n">get</span><span class="p">(</span><span class="s1">'test'</span><span class="p">,</span> <span class="s1">'inputs'</span><span class="p">,</span> <span class="s1">'bchw'</span><span class="p">)</span>
<span class="n">testTargets</span> <span class="o">=</span> <span class="n">ds</span><span class="p">:</span><span class="n">get</span><span class="p">(</span><span class="s1">'test'</span><span class="p">,</span> <span class="s1">'targets'</span><span class="p">,</span> <span class="s1">'b'</span><span class="p">)</span>
</code></pre>
</div>

<p>Note that the data, when retrieved, comes with a specific “view”. In tensors, the data is usually stored in a storage and retrieved with different views, since the world of neural network involves a constant reshaping of the data to match different calculation functions.</p>

<p>After the data is loaded as tensors, I then initiated a multi-layer perceptron using the <code class="highlighter-rouge">nn</code> package. Since a multi-layer perceptron is a feed forward network with fully connected layers, I can construct the model using the <code class="highlighter-rouge">nn.Sequential()</code> container. The container makes it possible for data scientist to plug in functions as if each function is a module. The underlying auto calculation of the gradient functions and network graph makes it extremely easy to code the core part of the network training/optimization.</p>

<div class="language-lua highlighter-rouge"><pre class="highlight"><code><span class="nb">require</span> <span class="s1">'nn'</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Module initiated:'</span><span class="p">)</span>
<span class="n">module</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">module</span><span class="p">:</span><span class="n">add</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Convert</span><span class="p">(</span><span class="s1">'bchw'</span><span class="p">,</span> <span class="s1">'bf'</span><span class="p">))</span>
<span class="n">module</span><span class="p">:</span><span class="n">add</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1</span><span class="o">*</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span> <span class="mi">20</span><span class="p">))</span>
<span class="n">module</span><span class="p">:</span><span class="n">add</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Tanh</span><span class="p">())</span>
<span class="n">module</span><span class="p">:</span><span class="n">add</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">module</span><span class="p">:</span><span class="n">add</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">LogSoftMax</span><span class="p">())</span>
<span class="n">module</span> <span class="o">=</span> <span class="n">module</span>
<span class="nb">print</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>
</code></pre>
</div>

<p>This simple MLP consists of a hidden layer of 20 neurons that flattens the input 2-d matrices (of size 28*28, corresponding to each picture) into 1-d vectors, feeds it to a linear transformation matrix, and applies a Tanh() activation function. The output layer takes in the output of the hidden layer and applies linear transformation with 10 neurons, with each corresponding to a class in the classification. The output LogSoftMax() function then applies rescaling and logarithm to the transformed vector, preparing it for classification error estimation.</p>

<p>With the MLP structure in place, I then move forward to initiate an error estimation function that is crucial for error estimation. When training a supervised machine training network, one needs to find a way to evaluation the error of the output (i.e. how close is current model’s predictions compared to the desired outputs) and then adjust the models with respect to that error. The model update can be done with different optimization algorithms, but the core concept lies in the mathematical reasoning that the gap between output and prediction in the final stage of the model can be minimized by moving the model’s weights towards a “global minimum” of the error estimation function. Therefore, in order to implement the optimization of a neural network, an error estimation criterion function and a model parameter optimization algorithm are necessary.</p>

<div class="language-lua highlighter-rouge"><pre class="highlight"><code><span class="nb">require</span> <span class="s1">'optim'</span>

<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">ClassNLLCriterion</span><span class="p">()</span>

<span class="k">function</span> <span class="nf">trainEpoch</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
    <span class="kd">local</span> <span class="n">idxs</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randperm</span><span class="p">(</span><span class="n">inputs</span><span class="p">:</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span> <span class="c1">-- create a random list for indexing</span>
    <span class="k">for</span> <span class="n">i</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">batch_size</span> <span class="k">do</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">+</span> <span class="n">batch_size</span> <span class="o">&gt;</span> <span class="n">inputs</span><span class="p">:</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="k">then</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="n">idxs</span><span class="p">:</span><span class="n">narrow</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">i</span><span class="p">)</span>
        <span class="k">else</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="n">idxs</span><span class="p">:</span><span class="n">narrow</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="k">end</span>
        <span class="kd">local</span> <span class="n">batchInputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">:</span><span class="n">index</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span><span class="n">long</span><span class="p">())</span>
        <span class="kd">local</span> <span class="n">batchLabels</span> <span class="o">=</span> <span class="n">targets</span><span class="p">:</span><span class="n">index</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span><span class="n">long</span><span class="p">())</span>
        <span class="kd">local</span> <span class="n">params</span><span class="p">,</span> <span class="n">gradParams</span> <span class="o">=</span> <span class="n">module</span><span class="p">:</span><span class="n">getParameters</span><span class="p">()</span>
        <span class="kd">local</span> <span class="n">optimState</span> <span class="o">=</span> <span class="p">{</span><span class="n">learningRate</span> <span class="o">=</span> <span class="mi">0</span><span class="p">.</span><span class="mi">1</span><span class="p">,</span> <span class="n">momentum</span> <span class="o">=</span> <span class="mi">0</span><span class="p">.</span><span class="mi">9</span><span class="p">}</span>
        <span class="k">function</span> <span class="nf">feval</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
            <span class="n">gradParams</span><span class="p">:</span> <span class="n">zero</span><span class="p">()</span>
            <span class="kd">local</span> <span class="n">outputs</span> <span class="o">=</span> <span class="n">module</span><span class="p">:</span><span class="n">forward</span><span class="p">(</span><span class="n">batchInputs</span><span class="p">)</span>
            <span class="kd">local</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">:</span><span class="n">forward</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">batchLabels</span><span class="p">)</span>
            <span class="kd">local</span> <span class="n">dloss_doutputs</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">:</span><span class="n">backward</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">batchLabels</span><span class="p">)</span>
            <span class="n">module</span><span class="p">:</span><span class="n">backward</span><span class="p">(</span><span class="n">batchInputs</span><span class="p">,</span> <span class="n">dloss_doutputs</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">gradParams</span>
        <span class="k">end</span>
        <span class="n">optim</span><span class="p">.</span><span class="n">sgd</span><span class="p">(</span><span class="n">feval</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">optimState</span><span class="p">)</span>
    <span class="k">end</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="kc">nil</span>
<span class="k">end</span>
</code></pre>
</div>

<p>As displayed in above code chunk, I used <code class="highlighter-rouge">nn.ClassNLLCriterion()</code> to estimate the classification errors; the function actually calculates the Cross Entropy Errors with the output from <code class="highlighter-rouge">nn.LogSoftMax()</code>. In my main <code class="highlighter-rouge">trainEpoch</code> function, I created a randomized mini-batch generator by packing the entries into small batches of equal size and feeding to the <code class="highlighter-rouge">module</code>. Then I calculates the <code class="highlighter-rouge">outputs</code>, <code class="highlighter-rouge">loss</code> (i.e. the errors) w.r.t. the <code class="highlighter-rouge">outputs</code> and <code class="highlighter-rouge">batchLabels</code>, the most important <code class="highlighter-rouge">dloss_doutputs</code> (gradient of the error with respect to the output), and the corresponding <code class="highlighter-rouge">gradParams</code> (model parameter’s corresponding gradients w.r.t. the <code class="highlighter-rouge">batchInputs</code> and the <code class="highlighter-rouge">dloss_doutputs</code>). The weight gradient is then fed to <code class="highlighter-rouge">optim.sgd()</code> for model parameter updates. Note that in real-life training, I will need to specify at least a learning rate for the <code class="highlighter-rouge">optim.sgd()</code> algorithm so that the optimization function knows how much of a change needs to be applied to the model for each mini-batch.</p>

<p>After the function is created, all I need to do is to write a loop that can go over all the data in epochs, evaluate the module performance, and adjust the meta-parameters of the training loop. I have uploaded my complete project report <a href="https://s3.amazonaws.com/elvinouyang.github.io/mid-term-chuanye-ouyang.html">here</a>. If you are interested in my full codes, please visit my GitHub project folder <a href="https://github.com/ElvinOuyang/deep-learning-resouces/tree/master/lua%20torch%20mnist%20mlp%20training">here</a></p>

<p>In my next post, I will recreate the module with python and PyTorch.</p>

        
      </section>

      <footer class="page__meta">
        
        
  


  
  
  

  <p class="page__taxonomy">
    <strong><i class="fa fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="http://localhost:4000/tags/#deep-learning" class="page__taxonomy-item" rel="tag">Deep Learning</a><span class="sep">, </span>
    
      
      
      <a href="http://localhost:4000/tags/#lua" class="page__taxonomy-item" rel="tag">Lua</a><span class="sep">, </span>
    
      
      
      <a href="http://localhost:4000/tags/#neural-network" class="page__taxonomy-item" rel="tag">Neural Network</a><span class="sep">, </span>
    
      
      
      <a href="http://localhost:4000/tags/#torch7" class="page__taxonomy-item" rel="tag">Torch7</a>
    
    </span>
  </p>




  


  
  
  

  <p class="page__taxonomy">
    <strong><i class="fa fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="http://localhost:4000/categories/#project" class="page__taxonomy-item" rel="tag">Project</a>
    
    </span>
  </p>


        
          <p class="page__date"><strong><i class="fa fa-fw fa-calendar" aria-hidden="true"></i> Updated:</strong> <time datetime="2017-09-30T00:00:00-04:00">September 30, 2017</time></p>
        
      </footer>

      

      
  <nav class="pagination">
    
      <a href="http://localhost:4000/project/reuters-w2v-bow-get-started/" class="pagination--pager" title="Applying Bag of Words and Word2Vec models on Reuters-21578 Dataset
">Previous</a>
    
    
      <a href="#" class="pagination--pager disabled">Next</a>
    
  </nav>

    </div>

    
      <div class="page__comments">
  
  
    <h4 class="page__comments-title">Leave a Comment</h4>
    <section id="disqus_thread"></section>
  
</div>

    
  </article>

  
  
</div>


    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    
    
    
    
      <li><a href="http://github.com/ElvinOuyang"><i class="fa fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
    
    
    <li><a href="http://localhost:4000/feed.xml"><i class="fa fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2017 Elvin Ouyang. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>
      </footer>
    </div>

    <script src="http://localhost:4000/assets/js/main.min.js"></script>




  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-96112090-1', 'auto');
  ga('send', 'pageview');
</script>







  
  <script type="text/javascript">
  	/* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
  	var disqus_shortname = 'elvinouyang-github-io';

  	/* * * DON'T EDIT BELOW THIS LINE * * */
  	(function() {
  		var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
  		dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  		(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  	})();

  	/* * * DON'T EDIT BELOW THIS LINE * * */
  	(function () {
  		var s = document.createElement('script'); s.async = true;
  		s.type = 'text/javascript';
  		s.src = '//' + disqus_shortname + '.disqus.com/count.js';
  		(document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
  	}());
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>






  </body>
</html>
